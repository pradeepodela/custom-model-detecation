{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "[[0.99999297 0.00000708]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import cv2\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = tensorflow.keras.models.load_model('keras_model.h5')\n",
    "#model = tensorflow.keras.models.load_model('model_resnet50.h5')\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image = Image.open('D:/drive-download-20210506T073815Z-001/Ambulance/45.jpg')\n",
    "\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# display the resized image\n",
    "#image.show()\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = model.predict(data)\n",
    "print(prediction)\n",
    "#print(prediction[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture('D:/dowanloadss/ambulance.mp4')\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10,150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "from recorder import Recorder\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import librosa\n",
    "from librosa import display\n",
    "from IPython.display import Audio\n",
    "from scipy.fft import fft, fftfreq\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "np.set_printoptions(suppress=True)\n",
    "model = tensorflow.keras.models.load_model('D:/dowanloadss/converted_keras (1)new/keras_model.h5')\n",
    "#model = tensorflow.keras.models.load_model('model_resnet50.h5')\n",
    "#model = tensorflow.keras.models.load_model('D:/dowanloadss/new model with accident/keras_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emergency():\n",
    "    \n",
    "    r = Recorder()\n",
    "    r.record(5, output='out.wav')\n",
    "    fname=\"out.wav\"\n",
    "    samples, sam_rate=librosa.load(fname, sr=None, mono=True, offset=0.0, duration=None)\n",
    "\n",
    "\n",
    "    Audio(fname)\n",
    "\n",
    "    #plt.figure()\n",
    "    #librosa.display.waveplot(y=samples, sr=sam_rate)\n",
    "    #plt.xlabel(\"time secs\")\n",
    "    #plt.ylabel(\"Ampl\")\n",
    "    #plt.show()\n",
    "\n",
    "    def fft_plot(audio, sam_rate):\n",
    "        n = len(audio)\n",
    "        T= 1/sam_rate\n",
    "        yf = fft(audio)\n",
    "        xf = fftfreq(n, T)#[:n//2]\n",
    "        #fig, ax = plt.subplots()\n",
    "        #plt.plot(xf, 2.0/n * np.abs(yf)) #np.abs(yf[0:n//2]))\n",
    "        #plt.grid()\n",
    "        #plt.xlabel(\"Freq\")\n",
    "        #plt.ylabel(\"mag\")\n",
    "        val=np.argmax(yf)\n",
    "        #plt.show()\n",
    "        return np.abs(xf[val])\n",
    "\n",
    "\n",
    "    audio_freq = fft_plot(samples, sam_rate)\n",
    "    freq = audio_freq.round()\n",
    "    if freq in range(700,1500):\n",
    "         cv2.putText(image,'Ambulance detecated',(450,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "    \n",
    "         print(\"it is a emergency vechicle\")\n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is a emergency vechicle\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "it is a emergency vechicle\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "it is a emergency vechicle\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n",
      "it is a emergency vechicle\n",
      "ambulance:1.0% firengine:0.0% policecar:0.0% trafic:0.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-678c5a0e0d2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mambulance\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ambulance:1.0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0memergency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfirengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'firengine:1.0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-c3dd573a3012>\u001b[0m in \u001b[0;36memergency\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRecorder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'out.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"out.wav\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msam_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\recorder.py\u001b[0m in \u001b[0;36mrecord\u001b[1;34m(self, duration, output)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36mwriteframes\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteframesraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datalength\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datawritten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_patchheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36m_patchheader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[0mcurpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_form_length_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<L'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m36\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datawritten\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_length_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    success, img = cap.read()\n",
    "    image = img\n",
    "    img = cv2.resize(img,(224,224))\n",
    "    img_res = np.asarray(img)\n",
    "    normalized_image_array = (img_res.astype(np.float32) / 127.0) - 1\n",
    "    data[0] = normalized_image_array\n",
    "    prediction = model.predict(data)\n",
    "    #print(prediction[0][0])\n",
    "    \n",
    "    #print(text)\n",
    "    ambulanc_acc =(prediction[0][0])\n",
    "    firengin_acc = [] \n",
    "    \n",
    "    ambulance = (f'ambulance:{prediction[0][0].round()}')\n",
    "    firengine = (f'firengine:{prediction[0][1].round()}')\n",
    "    policecar = (f'policecar:{prediction[0][2].round()}')\n",
    "    trafic =    (f'trafic:{prediction[0][3].round()}')\n",
    "    \n",
    "    \n",
    "    if ambulance == 'ambulance:1.0':\n",
    "        emergency()\n",
    "       \n",
    "    if firengine == 'firengine:1.0':\n",
    "        cv2.putText(image,'Firengine detecated',(450,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "    \n",
    "    if policecar == 'policecar:1.0':\n",
    "        cv2.putText(image,'Policecar detecated',(450,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        \n",
    "   # if trafic == 'trafic:1.0':\n",
    "       # cv2.putText(image,'trafic detecated',(50,150),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),2)\n",
    "        \n",
    "        \n",
    "    text = (f'{ambulance}% {firengine}% {policecar}% {trafic}%')\n",
    "    print(text)\n",
    "    \n",
    "    cv2.putText(image,text,(15,20),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),2)\n",
    "    cv2.imshow(\"Result\", image)\n",
    "    if cv2.waitKey(1) and 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ser = serial.Serial('COM4', 9600, timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    time.sleep(0.5)\n",
    "    ser.write(b'H')   # send the pyte string 'H'\n",
    "    time.sleep(0.5)   # wait 0.5 seconds\n",
    "    ser.write(b'L')   # send the byte string 'L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.write(b'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.write(b'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "def pri(i):\n",
    "    n = 0\n",
    "    if i == 's' and n == 0:\n",
    "        print('hellow world')\n",
    "        sleep(90)\n",
    "                \n",
    "    else:\n",
    "        print(f'still {n} is left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
